{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch_scatter\n",
    "import torch_geometric\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid('./data', 'Cora')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN Layer and GCN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "h_{v}^k = \\sigma\\left(W_k\\sum_{u \\in \\mathcal{N}(v)\\cup \\{v\\}} \\dfrac{h_{u}^{k-1}}{\\sqrt{|N(u)||N(v)|}} \\right) = \\sigma\\left(W_k\\sum_{u } h_{u}^{k-1}\\hat{A}_{uv} \\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "其中$\\hat{A}_{uv}$是归一化的邻接矩阵，即$\\hat{A} = D^{-1/2}AD^{-1/2}$，$D$是度数对角矩阵，$A$是增加了对角元后的邻接矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.W = nn.Linear(in_channels, out_channels)\n",
    "        self.act = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, A, X):\n",
    "        '''\n",
    "        A: adjacency matrix, shape: (N, N)\n",
    "        X: feature matrix, shape: (N, in_channels)\n",
    "        \n",
    "        return: shape: (N, out_channels)\n",
    "        '''\n",
    "        A = A + torch.eye(A.shape[0])\n",
    "        degree = torch.sum(A, dim=1)\n",
    "        D = torch.diag(1 / torch.sqrt(degree))\n",
    "        A_hat = D @ A @ D\n",
    "        X_hat = A_hat @ X\n",
    "        return self.act(self.W(X_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerGCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SingleLayerGCN, self).__init__()\n",
    "        self.gcn = GCNLayer(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, A, X):\n",
    "        return self.gcn(A, X)\n",
    "\n",
    "class MultiLayerGCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(MultiLayerGCN, self).__init__()\n",
    "        self.gcn1 = GCNLayer(in_channels, hidden_channels)\n",
    "        self.gcn2 = GCNLayer(hidden_channels, out_channels)\n",
    "    \n",
    "    def forward(self, A, X):\n",
    "        X = self.gcn1(A, X)\n",
    "        X = self.gcn2(A, X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-split train test data by 9:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2437, 271)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_train = data.x.shape[0] * 9 // 10\n",
    "all_samples = list(range(data.x.shape[0]))\n",
    "random.shuffle(all_samples)\n",
    "train_samples = all_samples[:N_train]\n",
    "test_samples = all_samples[N_train:]\n",
    "len(train_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = data.y.max() + 1\n",
    "n_features = data.x.shape[1]\n",
    "model_single = SingleLayerGCN(n_features, n_classes)\n",
    "model_multiple = MultiLayerGCN(n_features, 64, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(A, features, labels, train_idx, model, optimizer, epochs=100):\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(A, features)\n",
    "        loss_train = torch.nn.CrossEntropyLoss()(logits[train_idx], labels[train_idx])\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test(A, features, labels, test_idx, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(A, features)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        acc_test = int((pred[test_idx] == labels[test_idx]).sum()) / len(test_idx)\n",
    "        return acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_single = SingleLayerGCN(n_features, n_classes)\n",
    "model_multiple = MultiLayerGCN(n_features, 128, n_classes)\n",
    "optim_single = torch.optim.Adam(model_single.parameters(), lr=0.01)\n",
    "optim_multiple = torch.optim.Adam(model_multiple.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = to_dense_adj(data.edge_index)[0]\n",
    "features = data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:16<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "train(A, features, data.y, train_samples, model_single, optim_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8634686346863468"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(A, features, data.y, test_samples, model_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:24<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "train(A, features, data.y, train_samples, model_multiple, optim_multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9396799343455068"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(A, features, data.y, train_samples, model_multiple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: GCN with scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer_scatter(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNLayer_scatter, self).__init__()\n",
    "        self.W = nn.Linear(in_channels, out_channels)\n",
    "        self.act = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, edge_index, X):\n",
    "        '''\n",
    "        edge_index: [2, E]\n",
    "        x: input features, shape [N, in_channels],\n",
    "\n",
    "        return: shape [N, out_channels]\n",
    "        '''\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=X.size(0))\n",
    "        row, col = edge_index\n",
    "\n",
    "        deg = degree(col, X.size(0), dtype=X.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]    # (E,)\n",
    "\n",
    "        X = self.W(X)                                   # (N, out_channels)\n",
    "        X = X[edge_index[0]] * norm.unsqueeze(1)        # (E, out_channels)\n",
    "        \n",
    "        target = edge_index[1]                          # (E,)\n",
    "\n",
    "        out = torch_scatter.scatter(X, target, dim=0, reduce='sum')   # (N, out_channels)\n",
    "        return self.act(out)\n",
    "\n",
    "\n",
    "class SingleLayerGCN_scatter(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SingleLayerGCN_scatter, self).__init__()\n",
    "        self.gcn = GCNLayer_scatter(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, edge_index, X):\n",
    "        return self.gcn(edge_index, X)\n",
    "\n",
    "class MultiLayerGCN_scatter(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(MultiLayerGCN_scatter, self).__init__()\n",
    "        self.gcn1 = GCNLayer_scatter(in_channels, hidden_channels)\n",
    "        self.gcn2 = GCNLayer_scatter(hidden_channels, out_channels)\n",
    "    \n",
    "    def forward(self, edge_index, X):\n",
    "        X = self.gcn1(edge_index, X)\n",
    "        X = self.gcn2(edge_index, X)\n",
    "        return X        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scatter_single = SingleLayerGCN_scatter(in_channels=n_features, out_channels=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8634686346863468\n",
      "0.8634686346863468\n"
     ]
    }
   ],
   "source": [
    "model_scatter_single.eval()\n",
    "model_single.eval()\n",
    "with torch.no_grad():\n",
    "    model_scatter_single.gcn.W.weight = model_single.gcn.W.weight\n",
    "    print(test(data.edge_index, data.x, data.y, test_samples, model_scatter_single))\n",
    "    print(test(A, data.x, data.y, test_samples, model_single))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of time and memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def comp_scatter(num_nodes, edge_prob, n_features=128, out_channels=20):\n",
    "    model_scatter = SingleLayerGCN_scatter(n_features, out_channels)\n",
    "    X = torch.randn(num_nodes, n_features)\n",
    "    edge_index = torch_geometric.utils.erdos_renyi_graph(num_nodes, edge_prob)\n",
    "    start_time = time.time()\n",
    "    logits = model_scatter(edge_index, X)\n",
    "    print(\"Time taken: \", time.time() - start_time)\n",
    "def comp(num_nodes, edge_prob, n_features=128, out_channels=20):\n",
    "    model = SingleLayerGCN(n_features, out_channels)\n",
    "    X = torch.randn(num_nodes, n_features)\n",
    "    edge_index = torch_geometric.utils.erdos_renyi_graph(num_nodes, edge_prob)\n",
    "    A = torch_geometric.utils.to_dense_adj(edge_index)[0]\n",
    "    start_time = time.time()\n",
    "    logits = model(A, X)\n",
    "    print(\"Time taken: \", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "节点太多会爆内存且用时太久，因此选取的节点和边数比作业要求少"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用scatter的实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  5.369081735610962\n",
      "peak memory: 10287.58 MiB, increment: 10025.90 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "comp_scatter(20000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  1.2652032375335693\n",
      "peak memory: 2819.27 MiB, increment: 2639.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "comp_scatter(10000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  3.7466859817504883\n",
      "peak memory: 8087.11 MiB, increment: 7906.42 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "comp_scatter(10000, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  47.16345977783203\n",
      "peak memory: 9739.15 MiB, increment: 9558.45 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "comp_scatter(10000, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  0.2821488380432129\n",
      "peak memory: 706.67 MiB, increment: 593.97 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "comp_scatter(5000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  0.8651759624481201\n",
      "peak memory: 1959.32 MiB, increment: 1839.07 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "comp_scatter(5000, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  2.0101325511932373\n",
      "peak memory: 4729.50 MiB, increment: 4609.20 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "comp_scatter(5000, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用邻接矩阵的实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  205.634783744812\n",
      "peak memory: 9642.47 MiB, increment: 9531.35 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "comp(20000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  29.314781665802002\n",
      "peak memory: 2469.82 MiB, increment: 2331.17 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "comp(10000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  29.426659107208252\n",
      "peak memory: 2511.20 MiB, increment: 2370.11 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "comp(10000, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  27.021151542663574\n",
      "peak memory: 4998.66 MiB, increment: 4857.57 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "comp(10000, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  3.8847031593322754\n",
      "peak memory: 658.40 MiB, increment: 517.30 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "comp(5000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  3.6381733417510986\n",
      "peak memory: 734.85 MiB, increment: 593.72 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "comp(5000, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  3.6242895126342773\n",
      "peak memory: 1250.27 MiB, increment: 1109.14 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit \n",
    "comp(5000, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果\n",
    "\n",
    "运行时间上\n",
    "- 基于邻接矩阵的GCN时间只与节点数有关，大致为平方关系\n",
    "- 基于scatter的GCN时间与边数有关，大致为线性关系\n",
    "\n",
    "内存占用上\n",
    "- 基于scatter的GCN内存与边数有关，大致为线性关系\n",
    "- 基于邻接矩阵的GCN内存与节点数和边数均有关"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gomoku",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
